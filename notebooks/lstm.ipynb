{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "from typing import Dict, List\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device: str = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "        \n",
    "    pattern = r'([.,!?-])'\n",
    "    s = re.sub(pattern, r' \\1 ', text)    \n",
    "    s = re.sub(r'\\s{2,}', ' ', s)            \n",
    "    text = s\n",
    "\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', r'', text)\n",
    "\n",
    "    emojis = re.compile(\n",
    "        '['\n",
    "        u'\\U0001F600-\\U0001F64F'  # emoticons\n",
    "        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
    "        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
    "        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n",
    "        u'\\U00002702-\\U000027B0'\n",
    "        u'\\U000024C2-\\U0001F251'\n",
    "        ']+',\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    text = emojis.sub(r'', text)\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/IMDB.csv\")\n",
    "\n",
    "sentences = data[\"review\"].values\n",
    "words = \" \".join(sentences)\n",
    "words = clean_text(words)\n",
    "words = words.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, words: List[str], clean_text: bool = False) -> None:\n",
    "        counter = Counter(words)\n",
    "        self.vocab = sorted(counter, key=counter.get, reverse=True)\n",
    "        self.int2word = dict(enumerate(self.vocab, 1))\n",
    "        self.int2word[0] = \"<PAD>\"\n",
    "        self.word2int = {word: id for id, word in self.int2word.items()}\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def tokenize(self, sentence: str) -> List[str]:\n",
    "        return sentence.split()\n",
    "    \n",
    "    def convert_tokens_to_ids(self, tokens: List[str]) -> List[int]:\n",
    "        result = []\n",
    "        for word in tokens:\n",
    "          if word in self.word2int:\n",
    "            result.append(self.word2int[word])\n",
    "        return result\n",
    "    \n",
    "    def convert_ids_to_tokens(self, ids: List[int]) -> List[str]:\n",
    "            return [self.int2word[id] for id in ids]\n",
    "    \n",
    "tokenizer = Tokenizer(words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, root: str = \"../data/IMDB.csv\", train: bool = True, test_size: float = 0.33, tokenizer: Tokenizer = None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        data = pd.read_csv(root)\n",
    "        data = pd.get_dummies(data, columns=[\"sentiment\"])\n",
    "        data = data.rename({\"review\": \"sentence\", \n",
    "                            \"sentiment_negative\": \"negative\", \n",
    "                            \"sentiment_positive\": \"positive\"}, axis=1)\n",
    "        \n",
    "        X = data[\"sentence\"].values\n",
    "        y = data.drop([\"sentence\"], axis=1).values\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "        if train:\n",
    "            self.X, self.y = X_train, y_train\n",
    "        else:\n",
    "            self.X, self.y = X_test, y_test\n",
    "\n",
    "        self.tokenizer: Tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = clean_text(self.X[idx])\n",
    "        sentence = self.X[idx]\n",
    "        tokens = self.tokenizer.tokenize(sentence)\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        ids = torch.tensor(ids, dtype=torch.long)\n",
    "        labels = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        return ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = IMDBDataset(tokenizer=tokenizer)\n",
    "test_dataset = IMDBDataset(train=False, tokenizer=tokenizer)\n",
    "\n",
    "batch_size: int = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset)\n",
    "test_loader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmotionalLSTM(\n",
      "  (embedding): Embedding(10000, 256)\n",
      "  (lstm): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.25)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class EmotionalLSTM(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab_size: int, \n",
    "                 emb_size: int, \n",
    "                 hidden_size: int, \n",
    "                 num_stacked_layers: int = 3, \n",
    "                 dropout: float = 0.2) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, num_stacked_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_size, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.LongTensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:,-1,:]\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "vocab_size: int = 10000\n",
    "emb_size: int = 256\n",
    "hidden_size: int = 512\n",
    "num_stacked_layers: int = 2\n",
    "dropout: float = 0.25\n",
    "\n",
    "model: EmotionalLSTM = EmotionalLSTM(vocab_size, emb_size, hidden_size, num_stacked_layers, dropout).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33500/33500 [55:37<00:00, 10.04it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/8, Train Loss: 0.6937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33500/33500 [48:22<00:00, 11.54it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/8, Train Loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33500/33500 [32:49<00:00, 17.01it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/8, Train Loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33500/33500 [37:30<00:00, 14.89it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/8, Train Loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33500/33500 [1:06:44<00:00,  8.37it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/8, Train Loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33500/33500 [50:42<00:00, 11.01it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/8, Train Loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33500/33500 [54:34<00:00, 10.23it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/8, Train Loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33500/33500 [57:14<00:00,  9.76it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/8, Train Loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer: torch.optim.Optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion: nn.CrossEntropyLoss = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs: int = 8\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss: float = 0.0\n",
    "    for i, (sentences, labels) in enumerate(tqdm(train_loader)):\n",
    "        sentences = sentences.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(sentences)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16500/16500 [06:12<00:00, 44.32it/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49733333333333335"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = 0\n",
    "total_samples = 0\n",
    "\n",
    "loader = test_loader\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "for batch, (X, y) in enumerate(tqdm(loader)):\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X.to(device))\n",
    "    \n",
    "    y = y.to(device)\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    \n",
    "    # Convert one-hot encoded y to class indices if needed\n",
    "    if y.dim() == 2:\n",
    "        y = torch.argmax(y, dim=1)\n",
    "    \n",
    "    # Debug prints for shapes\n",
    "    correct_predictions = (predicted == y).sum().item()\n",
    "    accuracy += correct_predictions\n",
    "    total_samples += y.size(0)\n",
    "\n",
    "accuracy / (len(loader) * loader.batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
